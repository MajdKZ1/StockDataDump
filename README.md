# StockDataDump

StockDataDump is a high-throughput historical stock data dumper designed for large-scale quantitative research pipelines.  
It combines a **Rust-powered concurrent fetcher** with a **Python orchestration and conversion layer**, enabling rapid data acquisition, compact storage, and seamless transformation into analytics-ready formats.

## Overview

StockDataDump provides:

- **Rust hot-path fetcher**  
  Concurrent HTTP downloads using Tokio + Reqwest, streaming responses directly through zstd compression into `.zst` dump files.

- **Python orchestration layer**  
  Manifest generation, job scheduling, error handling, and conversion to columnar formats such as **Parquet** and **Feather** using pandas/pyarrow/numpy.

- **Optimized storage formats**  
  Raw dumps use zstd compression; converted Parquet outputs support zstd or snappy for fast reads and reduced disk usage.

This architecture allows capturing *large universes of symbols quickly*, while producing small, efficient datasets ideal for backtesting, machine learning, and long-horizon research.

---

## Repository Layout

```
rust-core/     # Rust fetcher (`dump-core`), built with Tokio + Reqwest + zstd
python/        # Python CLI (`stockdatadump`), manifest builder + converter
scripts/       # Helper scripts for install/clean/update workflows
dumps/         # Default output location for manifests, raw `.zst`, and Parquet files
```

---

## Quick Start

### 1. Build the Rust fetcher

```bash
cd rust-core
cargo build --release
```

### 2. Install the Python orchestrator

From the repository root:

```bash
pip install -e python
```

### 3. Optional helper scripts (Linux/macOS)

```bash
./scripts/interface.sh   # interactive menu: build, install, clean, update
./scripts/install.sh     # installs Rust core + Python tools
./scripts/clean.sh       # removes generated artifacts
./scripts/update.sh      # rebuilds Rust and reinstalls Python package
```

---

## Fetching and Converting Data

Yahoo Finance requires both a **crumb** and a **cookie**.  
These may be passed directly or exported as environment variables (`YAHOO_CRUMB`, `YAHOO_COOKIE`).

### 1. Generate a manifest

```bash
stockdatadump manifest AAPL MSFT SPY \
  -o dumps/manifests/yahoo.jsonl \
  --start 2023-01-01 \
  --crumb YOUR_CRUMB \
  --cookie "B=...; other cookies"
```

### 2. Fetch data using the Rust core

```bash
stockdatadump fetch \
  --manifest dumps/manifests/yahoo.jsonl \
  --output-dir dumps/raw \
  --concurrency 12
```

This writes compressed `.zst` files into `dumps/raw/`.

### 3. Convert raw dumps to Parquet

```bash
stockdatadump convert \
  --dumps-dir dumps/raw \
  --output dumps/arrow/dump.parquet \
  --format parquet \
  --compression zstd
```

---

## Inspecting Dumps

To quickly preview a compressed dump:

```bash
stockdatadump head dumps/raw/AAPL.zst
```

This decompresses the stream and prints the first few records.

---

## Manifest Format

The Rust `dump-core` fetcher expects **NDJSON**, where each line contains a `symbol` and a `url`:

```json
{"symbol": "AAPL", "url": "https://query1.finance.yahoo.com/v7/finance/download/AAPL?..."}
{"symbol": "MSFT", "url": "https://query1.finance.yahoo.com/v7/finance/download/MSFT?..."}
```

Manifests are fully generated by the CLI but can be manually constructed for custom data sources.

---

## License

This project is licensed under **OpenNET LLC**.
